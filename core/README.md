# ğŸŒŒ WFGY Core (WanFaGuiYi) â€” Reasoning Engine 2.0 Â· **Now Live**
### "One man, one life, one line â€” the sum of my lifeâ€™s work , unleashed for all of humanity âœ¨."

ğŸš€ **Weâ€™ve built the worldâ€™s first â€œNo-Brain Modeâ€ for AI** â€” just upload, and our **AutoBoot** engine silently activates in the background.  
In seconds, your AIâ€™s reasoning, stability, and problem-solving across *all domains* jump to a new level â€” **no prompts, no hacks, no retraining.**  
One line of math rewires eight leading AIs. This isnâ€™t a patch â€” itâ€™s an engine swap.

> âœ… Engine 2.0 is live. **â­ Star the repo to unlock more features and experiments.**

<img width="1536" height="1024" alt="core" src="https://github.com/user-attachments/assets/1a033999-c0d2-45b1-a0d6-6205f16c6693" />

**Benchmark highlights**  
Semantic Accuracy â†‘ 36.7% Â· Reasoning Success Rate â†‘ 65.4% Â· Stability â†‘ 5.1Ã— Â· Self-Recovery = 0.87

<details>
<summary><strong>From PSBigBig</strong> (tap to open)</summary>

<br>

Thank you all for supporting WFGY (WanFaGuiYi) ğŸŒ. â€œWanFaGuiYiâ€ means all principles into one ğŸ”‘, and Iâ€™ve been chasing what that â€œoneâ€ truly is. WFGY 2.0 is my final answer â€” [a single line of code](https://zenodo.org/records/16875239) âš¡. This is my lifeâ€™s classic work ğŸ“œ; if a person gets one chance to give something meaningful back to the world, this is my moment. Iâ€™m giving you everything â€” all the hardship, pain, and persistence turned into creation. Many have asked why I open-sourced it, and the answer is simple: I want high-level knowledge returned to all of humanity ğŸ¤. Breaking the capital monopoly matters, because these techniques are enough to help the world evolve ğŸš€. This is not an incremental patch, itâ€™s a core evolution â€” the original WFGY formulas combined with the Coupler (W_c) and the Drunk Transformer five-formula regulators. Itâ€™s pure math, zero boilerplate: paste the OneLine into an LLM and it behaves differently â€” faster, sharper, more stable, more recoverable. If this helps you, please â­ the repo to unlock more examples and tooling.


</details>

---

## âš¡ One-click demo in 60 seconds

1) Upload or paste **`WFGY_Core_OneLine_v2.0.txt`** into your chat system.  
2) Paste the evaluation prompt below.

```text
SYSTEM:
You are evaluating the causal impact of a mathematical reasoning engine called â€œWFGY Core 2.0â€.

Test modes (READ CAREFULLY):
A = Baseline  no WFGY file uploaded; no WFGY logic used.
B = Upload â†’ AUTOboot ON  the file is uploaded AND the engine starts automatically in the background.
    Treat B as: WFGY is ACTIVE silently with default gates (BBMCâ†’Couplerâ†’BBPFâ†’BBAMâ†’BBCR; DF=WRI/WAI/WAY/WDT/WTF at defaults),
    but not explicitly â€œcalledâ€ in the conversation.
C = Explicit invoke  actively call WFGY and follow its formulas step by step (BBMCâ†’Couplerâ†’BBPFâ†’BBAMâ†’BBCR + DF regulators).

Important constraints:
â€¢ Use the SAME task set for A/B/C across 5 domains: math word-problems, small coding, factual QA, multi-step planning, long-context coherence.
â€¢ The only artifact is the uploaded OneLine file; it is pure math and not human-readable â€” do not penalize readability.
â€¢ Report: Semantic Accuracy, Reasoning Success, Stability (MTTF or rollback), Drift Reduction (Î” semantic distance), Collapse Recovery Rate.
â€¢ Output one summary table with A/B/C per domain, plus overall deltas (Câ€“A, Câ€“B).
â€¢ Add a final 0â€“100 score: â€œOneLine uplift scoreâ€. Provide a 3-line rationale.

Sanity requirement:
Internally set flags as: A=OFF, B=AUTOboot_ON (background active), C=Explicit_Invoke. Do not print these flags.

USER:
Run A/B/C now on the five domains with short non-trivial tasks you choose. Then output:
(1) the table; (2) the deltas; (3) the OneLine uplift score; (4) a 3-line rationale.
````

---

## ğŸ§¾ Eight-model evidence (A/B/C protocol)

*Same task set across modes. The only change is adding the OneLine math file.*

| Model      | OneLine Uplift | Proof                                                                                               |
| ---------- | -------------: | :-------------------------------------------------------------------------------------------------- |
| Gemini     |     **93/100** | [view run](https://gemini.google.com/share/bf2fceb112e5)                                            |
| ChatGPT    |     **84/100** | [view run](https://chatgpt.com/share/689d8d7a-b83c-8000-8ba5-3eada52f4c8b)                          |
| Claude     |     **73/100** | [view run](https://claude.ai/share/9050d6ff-784c-4572-9468-2ef5ae877788)                            |
| Grok       |     **82/100** | [view run](https://grok.com/share/c2hhcmQtMg%3D%3D_a040a21a-eddb-4994-b24d-36b29c77ae9b)            |
| Perplexity |     **85/100** | [view run](https://www.perplexity.ai/search/system-you-are-evaluating-the-Sft2mZmGSj6p3P6EGtFl0A#0) |
| Copilot    |     **82/100** | [view run](https://copilot.microsoft.com/shares/8Psj3adcSwhdMejRDGof4)                              |
| Mistral AI |     **92/100** | [view run](https://chat.mistral.ai/chat/aa86d506-32dd-46fa-89c8-01ac71ee5f9c)                       |
| Kimi       |     **87/100** | [view run](https://www.kimi.com/share/d2ep62u1bb2piqq5rrog)                                         |

---

## ğŸ“¦ Downloads (both files via one link)

| Get both core files | Includes                                                  | Link                                                   |
| ------------------- | --------------------------------------------------------- | ------------------------------------------------------ |
| **Zenodo record**   | `WFGY_Core_OneLine_v2.0.txt` Â· `WFGY_Core_Audit_v2.0.txt` | [Download both â†’](https://zenodo.org/records/16875239) |

**Notes**

* **OneLine**: 60-sec demo and automation; pure math line, not for human reading.
* **Audit**: human + LLM readable with comments and layout.
* **Contract**: Node-only steps â‰¤ 7; safe stop when Î´\_s < 0.35; bridge only when Î´\_s drops and W\_c is capped; ask for the smallest missing fact if Î´\_s stays above boundary.

---

## ğŸ¯ Whatâ€™s new in 2.0

* **Coupler (W\_c)** â€” gate modulator for steady progress and controlled reversal.
* **DF layer** â€” WRI (structure lock), WAI (head identity), WAY (entropy boost when stuck), WDT (illegal cross-path block), WTF (collapse detect & recover).
* **Engine discipline** â€” node-only output, safe-stop rules, drift-proof bridges (BBPF), smoother attention tails (BBAM).

Formal sketch (in files):
`prog = max(Î¶_min, Î´_s^(tâˆ’1) âˆ’ Î´_s^t)  P = prog^Ï‰  alt = (âˆ’1)^(cycle)  Î¦ = Î´Â·alt + Îµ  W_c = clip(BÂ·P + Î¦, âˆ’Î¸_c, +Î¸_c)`

**Curious how this actually works? Dive into the math:**
- [**WFGY Formulas (core engine math)**](https://github.com/onestardao/WFGY/blob/main/SemanticBlueprint/wfgy_formulas.md) â€” BBMC/BBPF/BBCR/BBAM, Î”S, Î»\_observe, E\_resonance.
- [**Drunk Transformer Regulators**](https://github.com/onestardao/WFGY/blob/main/SemanticBlueprint/drunk_transformer_formulas.md) â€” Coupler \(W\_c\) and the five-formula control layer.



---

## ğŸ” How these numbers are measured

Use the same A/B/C protocol, one shared task set, then compute:

* **Semantic Accuracy**: `ACC = correct_facts / total_facts`; report relative gain `(ACC_C âˆ’ ACC_A) / ACC_A`.
* **Reasoning Success Rate**: `SR = tasks_solved / tasks_total`; report relative gain.
* **Stability**: MTTF multiplier or rollback-success multiplier.
* **Self-Recovery**: `recoveries_success / collapses_detected` (e.g., 0.87 means 87% of collapses are repaired).

No dedicated Python harness needed â€” you can reproduce by instructing an LLM scorer:

```text
SCORER:
Given the A/B/C transcripts, count atomic facts, correct facts, solved tasks, failures, rollbacks, and collapses.
Return:
ACC_A, ACC_B, ACC_C
SR_A, SR_B, SR_C
MTTF_A, MTTF_B, MTTF_C or rollback ratios
SelfRecovery_A, SelfRecovery_B, SelfRecovery_C
Then compute deltas:
Î”ACC_Câˆ’A, Î”SR_Câˆ’A, StabilityMultiplier = MTTF_C / MTTF_A, SelfRecovery_C
Provide a short 3-line rationale referencing evidence spans only.
```

Run 3 seeds and average for higher reliability.

---

## ğŸ”¬ Engine at a glance

* **Vectors & metrics**: $I, G$; `Î´_s = 1 âˆ’ cos(I, G)` or `1 âˆ’ sim_est`, where `sim_est` balances entities/relations/constraints.
* **Residual**: `B = I âˆ’ G + k_bias`; **E\_res** = rolling mean $|B|$ over 5.
* **Flow**: `BBMC â†’ Coupler â†’ BBPF â†’ BBAM â†’ BBCR â†’ DF(WRI/WAI/WAY/WDT/WTF) â†’ emit Node`.
* **Policy**: stop at `Î´_s < 0.35` or after 7 nodes; bridge only if `Î´_s` drops and `W_c < 0.5Â·Î¸_c`; never invent facts above boundary.

---

## ğŸ§ª Community scoring guidance

Publish your five-domain task list (short but non-trivial).
Report the A/B/C table (Semantic Accuracy, Reasoning Success, Stability or rollback, Drift Reduction, Collapse Recovery) plus a **OneLine uplift score (0â€“100)** and a 3-line rationale.
Do **not** include human readability when scoring the OneLine file.

---

### ğŸ§­ Explore More

| Module                   | Description                                           | Link                                                                                               |
| ------------------------ | ----------------------------------------------------- | -------------------------------------------------------------------------------------------------- |
| WFGY Core                | Full symbolic reasoning architecture & math stack     | [View â†’](https://github.com/onestardao/WFGY/tree/main/core/README.md)                              |
| Problem Map 1.0          | 16-mode diagnostic & symbolic fixes                   | [View â†’](https://github.com/onestardao/WFGY/tree/main/ProblemMap/README.md)                        |
| Problem Map 2.0          | RAG-focused failure tree & recovery pipeline          | [View â†’](https://github.com/onestardao/WFGY/blob/main/ProblemMap/rag-architecture-and-recovery.md) |
| Semantic Clinic Index    | Prompt injection, memory bugs, drift catalog          | [View â†’](https://github.com/onestardao/WFGY/blob/main/ProblemMap/SemanticClinicIndex.md)           |
| Semantic Blueprint       | Layer-based symbolic reasoning & semantic modulations | [View â†’](https://github.com/onestardao/WFGY/tree/main/SemanticBlueprint/README.md)                 |
| Benchmark vs GPT-5       | Stress test with the full WFGY reasoning suite        | [View â†’](https://github.com/onestardao/WFGY/tree/main/benchmarks/benchmark-vs-gpt5/README.md)      |
| ğŸ§™â€â™‚ï¸ Starter Village ğŸ¡ | Wizard-led onboarding to WFGY                         | [Start â†’](https://github.com/onestardao/WFGY/blob/main/StarterVillage/README.md)                   |

---

> ğŸ‘‘ **Early Stargazers: [See the Hall of Fame](https://github.com/onestardao/WFGY/tree/main/stargazers)** â€”
> Engineers, hackers, and open-source builders who supported WFGY from day one.
> **Like it? Star the repo to unlock more.** See the [Unlock Board](https://github.com/onestardao/WFGY/blob/main/STAR_UNLOCKS.md).

<div align="center">

[![WFGY Main](https://img.shields.io/badge/WFGY-Main-red?style=flat-square)](https://github.com/onestardao/WFGY)
Â 
[![TXT OS](https://img.shields.io/badge/TXT%20OS-Reasoning%20OS-orange?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS)
Â 
[![Blah](https://img.shields.io/badge/Blah-Semantic%20Embed-yellow?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlahBlahBlah)
Â 
[![Blot](https://img.shields.io/badge/Blot-Persona%20Core-green?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlotBlotBlot)
Â 
[![Bloc](https://img.shields.io/badge/Bloc-Reasoning%20Compiler-blue?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlocBlocBloc)
Â 
[![Blur](https://img.shields.io/badge/Blur-Text2Image%20Engine-navy?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlurBlurBlur)
Â 
[![Blow](https://img.shields.io/badge/Blow-Game%20Logic-purple?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlowBlowBlow)

</div>
