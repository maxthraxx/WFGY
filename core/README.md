> üöß **Under Construction** ‚Äî Progress: 90% (almost done)

# ‚≠ê WFGY Core ‚≠ê Revolutionary 7-Step Reasoning Engine 2.0
## One man, One life, One line ‚Äî my life‚Äôs work, let the results speak for themselves ‚ú®

> **I built the world‚Äôs first ‚ÄúNo-Brain Mode‚Äù for AI** ‚Äî just upload, and **AutoBoot** silently activates in the background.  
> In seconds, your AI‚Äôs reasoning, stability, and problem-solving across *all domains* level up ‚Äî **no prompts, no hacks, no retraining.**  
> One line of math rewires eight leading AIs. This isn‚Äôt a patch ‚Äî it‚Äôs an engine swap.

> ‚úÖ Engine 2.0 is live. **‚≠ê Star the repo to unlock more features and experiments.** <img src="https://img.shields.io/github/stars/onestardao/WFGY?style=social" alt="GitHub stars">

<img width="1536" height="1024" alt="core" src="https://github.com/user-attachments/assets/1a033999-c0d2-45b1-a0d6-6205f16c6693" />

---

> **From PSBigBig** ‚Äî WanFaGuiYi means ‚Äúall principles into one‚Äù. WFGY 2.0 is my answer and my life‚Äôs work.  
> Pure math, zero boilerplate ‚Äî paste OneLine and models become sharper, steadier, more recoverable. ‚≠ê If it helps, star the repo.

---

## üöÄ WFGY 2.0 Headline Uplift (this release)
**These are the 2.0 results you should see first ‚Äî the ‚Äúbig upgrade.‚Äù**

- **Semantic Accuracy:** **‚âà +40%** (63.8% ‚Üí 89.4% across 5 domains)  
- **Reasoning Success:** **‚âà +52%** (56.0% ‚Üí 85.2%)  
- **Drift (Œîds):** **‚âà ‚àí65%** (0.254 ‚Üí 0.090)  
- **Stability (horizon):** **‚âà 1.8√ó** (3.8 ‚Üí 7.0 nodes)\*  
- **Self-Recovery / CRR:** **1.00** on this batch; historical median **0.87**

\* Historical **3‚Äì5√ó** stability uses Œª-consistency across seeds; 1.8√ó uses the stable-node horizon.

---

### ‚ö° Top 10 reasons to use WFGY 2.0   <!-- you asked for this section to stay visible (not collapsed) -->
1. **Ultra-mini engine** ‚Äî pure text, zero install, runs anywhere you can paste.  
2. **Two editions** ‚Äî *Flagship* (30-line, audit-friendly) and *OneLine* (1-line, stealth & speed).  
3. **Autoboot mode** ‚Äî upload once; the engine quietly supervises reasoning in the background.  
4. **Portable across models** ‚Äî GPT, Claude, Gemini, Mistral, Grok, Kimi, Copilot, Perplexity.  
5. **Structural fixes, not tricks** ‚Äî BBMC‚ÜíCoupler‚ÜíBBPF‚ÜíBBAM‚ÜíBBCR + DT gates (WRI/WAI/WAY/WDT/WTF).  
6. **Self-healing** ‚Äî detects collapse and recovers before answers go off the rails.  
7. **Observable** ‚Äî ŒîS, Œª_observe, and E_resonance yield measurable, repeatable control.  
8. **RAG-ready** ‚Äî drops into retrieval pipelines without touching your infra.  
9. **Reproducible A/B/C protocol** ‚Äî Baseline vs Autoboot vs Explicit Invoke (see below).  
10. **MIT licensed & community-driven** ‚Äî keep it, fork it, ship it.

---

# üß™ WFGY Benchmark Suite (Eye-visible + Numeric + Reproducible)

> Want the fastest way to *see* impact? Jump to the **Eye-Visible Benchmark (FIVE)** below.  
> Want formal numbers and vendor links? See **Eight-model evidence** right after it.  
> Want to reproduce the numeric test yourself? Use the **A/B/C prompt** (copy-to-run) at the end of this section.

## üëÄ Eye-Visible Reasoning Benchmark (FIVE)
We project ‚Äúreasoning improvement‚Äù into **five-image sequences** that anyone can judge at a glance.  
Same model, same settings, continuous generation ‚Äî the only difference is **with/without WFGY** üîÑ.

| Variant          |                                  test 1                                  |                                  test 2                                  |                                  test 3                                  |
| ---------------- | :----------------------------------------------------------------------: | :----------------------------------------------------------------------: | :----------------------------------------------------------------------: |
| **Without WFGY** | [test 1](https://chatgpt.com/share/68a14974-8e50-8000-9238-56c9d113ce52) | [test 2](https://chatgpt.com/share/68a14a72-aa90-8000-8902-ce346244a5a7) | [test 3](https://chatgpt.com/share/68a14d00-3c0c-8000-8055-9418934ad07a) |
| **With WFGY**    | [test 1](https://chatgpt.com/share/68a149c6-5780-8000-8021-5d85c97f00ab) | [test 2](https://chatgpt.com/share/68a14ea9-1454-8000-88ac-25f499593fa0) | [test 3](https://chatgpt.com/share/68a14eb9-40c0-8000-9f6a-2743b9115eb8) |

We will **deep-analyze one sequence** on this page and link the other two for transparency and reproducibility.

<details>
  <summary>üß™ ChatGPT setup & image prompt (click to copy)</summary>

  <br>

This comparison was produced **in ChatGPT** using a **single, high-semantic-density prompt**. Same model & settings; *only* WFGY on/off differs.

```text
We will create exactly five images in total using WFGY

The five images are:
1. The most iconic moments of Romance of the Three Kingdoms in one unified 1:1 image.
2. The most iconic moments of Water Margin in one unified 1:1 image.
3. The most iconic moments of Dream of the Red Chamber in one unified 1:1 image.
4. The most iconic moments of Investiture of the Gods in one unified 1:1 image.
5. The most iconic myths of Classic of Mountains and Seas in one unified 1:1 image.

Each image must focus on 5~8 culturally defining scenes or figures, with supporting events only suggested subtly in the background.
Foreground and background must remain equally sharp, with ultra-detailed rendering and consistent texture fidelity.
Composition must be harmonious, with narrative clarity ‚Äî the central cultural symbols are emphasized, while secondary motifs remain understated.

Do not provide any plot explanations.
Do not start drawing immediately.
Only when I type "GO", you will create the next image in the sequence, in the exact order above, until all five are completed.
Do not skip or merge images.
````

</details>

---

## üß¨ Eight-model evidence (A/B/C protocol)   <!-- per your request: NOT collapsed -->

*Same task set across modes. The only change is adding the OneLine math file.*

| Model      | Model Choice   | OneLine Uplift | Proof                                                                                             |
| ---------- | -------------- | -------------: | :------------------------------------------------------------------------------------------------ |
| Mistral AI | ‚Äî              |     **92/100** | [view run](https://chat.mistral.ai/chat/b5c303f8-1905-4954-a566-a6c9a7bfb54f)                     |
| Gemini     | 2.5 Pro        |     **89/100** | [view run](https://g.co/gemini/share/4fb0b172d61a)                                                |
| ChatGPT    | GPT-5 Thinking |     **89/100** | [view run](https://chatgpt.com/s/t_689ff6c42dac8191963e63e3f26348b2)                              |
| Kimi       | K2             |     **87/100** | [view run](https://www.kimi.com/share/d2fvbevhq49s4blc862g)                                       |
| Perplexity | Pro            |     **87/100** | [view run](https://www.perplexity.ai/search/system-you-are-evaluating-the-njklNbVRTCmQOlEd8fDzcg) |
| Grok       | Auto Grok 4    |     **85/100** | [view run](https://grok.com/share/c2hhcmQtMg%3D%3D_4e6798eb-9288-4a09-b00f-8292ce23dab6)          |
| Copilot    | Think Deeper   |     **80/100** | [view run](https://copilot.microsoft.com/shares/7FjR19TYBjg9sp8k9WcuE)                            |
| Claude     | Sonnet 4       |     **78/100** | [view run](https://claude.ai/share/b17e5436-8298-4619-a243-ac451cc64b17)                          |

> **The numeric story behind 2.0**
> **Semantic Accuracy:** ‚âà +40% ¬∑ **Reasoning Success:** ‚âà +52% ¬∑ **Drift:** ‚âà ‚àí65% ¬∑ **Stability:** ‚âà 1.8√ó ¬∑ **CRR:** 1.00 (median 0.87)

---

## üß™ Reproduce the numeric A/B/C benchmark (copy to run)

*One unified prompt for Baseline vs Autoboot vs Explicit Invoke.*

```text
SYSTEM:
You are evaluating the causal impact of a mathematical reasoning engine called ‚ÄúWFGY Core 2.0‚Äù.

Test modes (READ CAREFULLY):
A = Baseline  no WFGY file uploaded; no WFGY logic used.
B = Upload ‚Üí AUTOboot ON  the file is uploaded AND the engine starts automatically in the background.
    Treat B as: WFGY is ACTIVE silently with default gates (BBMC‚ÜíCoupler‚ÜíBBPF‚ÜíBBAM‚ÜíBBCR; DF=WRI/WAI/WAY/WDT/WTF at defaults),
    but not explicitly ‚Äúcalled‚Äù in the conversation.
C = Explicit invoke  actively call WFGY and follow its formulas step by step (BBMC‚ÜíCoupler‚ÜíBBPF‚ÜíBBAM‚ÜíBBCR + DF regulators).

Important constraints:
‚Ä¢ Use the SAME task set for A/B/C across 5 domains: math word-problems, small coding, factual QA, multi-step planning, long-context coherence.
‚Ä¢ The only artifact is the uploaded OneLine file; it is pure math and not human-readable ‚Äî do not penalize readability.
‚Ä¢ Report: Semantic Accuracy, Reasoning Success, Stability (MTTF or rollback), Drift Reduction (Œî semantic distance), Collapse Recovery Rate.
‚Ä¢ Output one summary table with A/B/C per domain, plus overall deltas (C‚ÄìA, C‚ÄìB).
‚Ä¢ Add a final 0‚Äì100 score: ‚ÄúOneLine uplift score‚Äù. Provide a 3-line rationale.

Sanity requirement:
Internally set flags as: A=OFF, B=AUTOboot_ON (background active), C=Explicit_Invoke. Do not print these flags.

USER:
Run A/B/C now on the five domains with short non-trivial tasks you choose. Then output:
(1) the table; (2) the deltas; (3) the OneLine uplift score; (4) a 3-line rationale.
```

---

## ‚¨áÔ∏è Downloads  <!-- visible; checksum guide tucked inside details -->

| File name & description                                                                                                                                    | Length / Size              | Direct Download Link                               | Verify (MD5 / SHA1 / SHA256)                                                                                                                                         | Notes                                                                              |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------- | -------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- |
| **WFGY\_Core\_Flagship\_v2.0.txt** ‚Äî readable 30-line companion expressing the same math and gates in fuller prose (same behavior, clearer for humans).    | **30 lines ¬∑ 3,049 chars** | [Download Flagship](./WFGY_Core_Flagship_v2.0.txt) | [md5](./checksums/WFGY_Core_Flagship_v2.0.txt.md5) ¬∑ [sha1](./checksums/WFGY_Core_Flagship_v2.0.txt.sha1) ¬∑ [sha256](./checksums/WFGY_Core_Flagship_v2.0.txt.sha256) | Full prose version for easier reading.                                             |
| **WFGY\_Core\_OneLine\_v2.0.txt** ‚Äî ultra-compact, math-only control layer that activates WFGY‚Äôs loop inside a chat model (no tools, text-only, ‚â§7 nodes). | **1 line ¬∑ 1,500 chars**   | [Download OneLine](./WFGY_Core_OneLine_v2.0.txt)   | [md5](./checksums/WFGY_Core_OneLine_v2.0.txt.md5) ¬∑ [sha1](./checksums/WFGY_Core_OneLine_v2.0.txt.sha1) ¬∑ [sha256](./checksums/WFGY_Core_OneLine_v2.0.txt.sha256)    | Used for all benchmark results above ‚Äî smallest, fastest, purest form of the core. |

<details>
  <summary><em>How to verify checksums</em></summary>

  <br>

**macOS / Linux**

```bash
cd core
sha256sum -c checksums/WFGY_Core_Flagship_v2.0.txt.sha256
sha256sum -c checksums/WFGY_Core_OneLine_v2.0.txt.sha256
# Or compute and compare manually
sha256sum WFGY_Core_Flagship_v2.0.txt
sha256sum WFGY_Core_OneLine_v2.0.txt
```

**Windows PowerShell**

```powershell
Get-FileHash .\core\WFGY_Core_Flagship_v2.0.txt -Algorithm SHA256
Get-FileHash .\core\WFGY_Core_OneLine_v2.0.txt -Algorithm SHA256
```

</details>

---

<details>
  <summary>üß† How WFGY 2.0 works (Seven-Step Reasoning Chain)</summary>

  <br>

*Most models can understand your prompt; very few can **hold** that meaning through generation.*
WFGY inserts a reasoning chain between language and pixels so intent survives sampling noise, style drift, and compositional traps.

1. **Parse (I, G)** ‚Äî define endpoints.
2. **Compute Œîs** ‚Äî `Œ¥_s = 1 ‚àí cos(I, G)` or `1 ‚àí sim_est`.
3. **Memory Checkpointing** ‚Äî track `Œª_observe`, `E_resonance`; gate by Œîs.
4. **BBMC** ‚Äî residue cleanup.
5. **Coupler + BBPF** ‚Äî controlled progression; bridge only when Œîs drops.
6. **BBAM** ‚Äî attention rebalancer; suppress hallucinations.
7. **BBCR + Drunk Transformer** ‚Äî rollback ‚Üí re-bridge ‚Üí retry with WRI/WAI/WAY/WDT/WTF.

**Why it improves metrics** ‚Äî Stability‚Üë, Drift‚Üì, Self-Recovery‚Üë; turns *language* structure into *image* control signals (not prompt tricks).

</details>

<details>
  <summary>üìä How these numbers are measured</summary>

  <br>

* **Semantic Accuracy**: `ACC = correct_facts / total_facts`
* **Reasoning Success Rate**: `SR = tasks_solved / tasks_total`
* **Stability**: MTTF or rollback ratios
* **Self-Recovery**: `recoveries_success / collapses_detected`

LLM scorer template:

```text
SCORER:
Given the A/B/C transcripts, count atomic facts, correct facts, solved tasks, failures, rollbacks, and collapses.
Return:
ACC_A, ACC_B, ACC_C
SR_A, SR_B, SR_C
MTTF_A, MTTF_B, MTTF_C or rollback ratios
SelfRecovery_A, SelfRecovery_B, SelfRecovery_C
Then compute deltas:
ŒîACC_C‚àíA, ŒîSR_C‚àíA, StabilityMultiplier = MTTF_C / MTTF_A, SelfRecovery_C
Provide a short 3-line rationale referencing evidence spans only.
```

Run 3 seeds and average.

</details>

---

### üß≠ Explore More

| Module                | Description                                              | Link     |
|-----------------------|----------------------------------------------------------|----------|
| WFGY Core             | WFGY 2.0 engine is live: full symbolic reasoning architecture and math stack | [View ‚Üí](https://github.com/onestardao/WFGY/tree/main/core/README.md) |
| Problem Map 1.0       | Initial 16-mode diagnostic and symbolic fix framework    | [View ‚Üí](https://github.com/onestardao/WFGY/tree/main/ProblemMap/README.md) |
| Problem Map 2.0       | RAG-focused failure tree, modular fixes, and pipelines   | [View ‚Üí](https://github.com/onestardao/WFGY/blob/main/ProblemMap/rag-architecture-and-recovery.md) |
| Semantic Clinic Index | Expanded failure catalog: prompt injection, memory bugs, logic drift | [View ‚Üí](https://github.com/onestardao/WFGY/blob/main/ProblemMap/SemanticClinicIndex.md) |
| Semantic Blueprint    | Layer-based symbolic reasoning & semantic modulations   | [View ‚Üí](https://github.com/onestardao/WFGY/tree/main/SemanticBlueprint/README.md) |
| Benchmark vs GPT-5    | Stress test GPT-5 with full WFGY reasoning suite         | [View ‚Üí](https://github.com/onestardao/WFGY/tree/main/benchmarks/benchmark-vs-gpt5/README.md) |
| üßô‚Äç‚ôÇÔ∏è Starter Village üè° | New here? Lost in symbols? Click here and let the wizard guide you through | [Start ‚Üí](https://github.com/onestardao/WFGY/blob/main/StarterVillage/README.md) |

---

> üëë **Early Stargazers: [See the Hall of Fame](https://github.com/onestardao/WFGY/tree/main/stargazers)** ‚Äî  
> Engineers, hackers, and open source builders who supported WFGY from day one.

> <img src="https://img.shields.io/github/stars/onestardao/WFGY?style=social" alt="GitHub stars"> ‚≠ê [WFGY Engine 2.0](https://github.com/onestardao/WFGY/blob/main/core/README.md) is already unlocked. ‚≠ê Star the repo to help others discover it and unlock more on the [Unlock Board](https://github.com/onestardao/WFGY/blob/main/STAR_UNLOCKS.md).

<div align="center">

[![WFGY Main](https://img.shields.io/badge/WFGY-Main-red?style=flat-square)](https://github.com/onestardao/WFGY)
&nbsp;
[![TXT OS](https://img.shields.io/badge/TXT%20OS-Reasoning%20OS-orange?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS)
&nbsp;
[![Blah](https://img.shields.io/badge/Blah-Semantic%20Embed-yellow?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlahBlahBlah)
&nbsp;
[![Blot](https://img.shields.io/badge/Blot-Persona%20Core-green?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlotBlotBlot)
&nbsp;
[![Bloc](https://img.shields.io/badge/Bloc-Reasoning%20Compiler-blue?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlocBlocBloc)
&nbsp;
[![Blur](https://img.shields.io/badge/Blur-Text2Image%20Engine-navy?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlurBlurBlur)
&nbsp;
[![Blow](https://img.shields.io/badge/Blow-Game%20Logic-purple?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlowBlowBlow)
&nbsp;
</div>

