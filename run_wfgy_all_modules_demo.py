# run_wfgy_all_modules_demo.py

from wfgy_sdk import enable, bbmc, bbpf, bbcr, bbam
from transformers import pipeline, set_seed
import numpy as np

# === 1. å•Ÿå‹•æ¨¡å‹èˆ‡ enable ===
set_seed(42)
generator = pipeline("text-generation", model="gpt2", device=-1)

# æ¨¡æ“¬ä¸€å€‹ dummy æ¨¡å‹ç‹€æ…‹
model_state = {
    "I": np.array([1.2, 0.8, 0.5]),
    "G": np.array([1.0, 0.7, 0.4]),
    "state": np.array([0.1, 0.2, 0.3]),
    "attention_logits": np.array([1.2, 0.9, 1.1])
}

model_state = enable(model_state)
print("\nâœ… WFGY Enabled.\n")

# === 2. æ¸¬è©¦å››å¤§æ¨¡çµ„ ===
print("ğŸ“Š BBMC Test:")
bbmc.run_demo()

print("\nâš™ï¸ BBPF Test:")
bbpf.run_demo()

print("\nğŸ•¸ï¸ BBCR Test:")
bbcr.run_demo()

print("\nğŸ” BBAM Test:")
bbam.run_demo()

# === 3. èªè¨€æ¨¡å‹å‰å¾Œæ¸¬è©¦ ===
prompt = "Describe the purpose of human consciousness using physics terms."

print("\n=== ğŸ”¹ Prompt ===")
print(prompt)

print("\n=== ğŸ§  Before WFGY ===")
before = generator(prompt, max_new_tokens=30, num_return_sequences=1)[0]["generated_text"]
print(before)

print("\n=== ğŸ§ª After WFGY (Semantic modulation active) ===")
# æ¨¡æ“¬é–‹å•Ÿ WFGY è™•ç†ï¼ˆé€™è£¡ç°¡åŒ–ï¼Œå¯¦éš›å¯é€²ä¸€æ­¥æ•´åˆï¼‰
model_state = enable(model_state)
after = generator(prompt, max_new_tokens=30, num_return_sequences=1)[0]["generated_text"]
print(after)

print("\nâœ… WFGY å››æ¨¡çµ„æ¸¬è©¦å®Œæˆï¼")
