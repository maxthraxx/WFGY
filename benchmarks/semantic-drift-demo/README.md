
# Semanticâ€‘DriftÂ DemoÂ ğŸ“

> *A minimal, fullyâ€‘reproducible experiment to **prove** how the WFGYÂ framework cuts semantic drift in multiâ€‘step reasoning.*

This demo compares plain LLM answers (**Baseline**) to **WFGYâœšDrunkMode** on **30 carefullyâ€‘crafted prompts**.  
The prompts come from the [**WFGYÂ 1.0 â€“ All Principles Return to One**](https://doi.org/10.5281/zenodo.15630969) public PDF, and specifically target longâ€‘chain reasoning weaknesses documented in **SectionÂ 3** of that paper.

> Unlike generic QA tests, this benchmark does **not** evaluate factual correctness or syntax.  
> Instead, it tests **semantic integrity** â€” whether the model preserves meaning over multi-hop chains.  
> It was derived directly from Section 3 of the WFGY1.0 paper and quantifies how Î”S and Î»_observe  
> reflect a modelâ€™s ability to avoid drift as reasoning unfolds.


---

## 1.Â Why run this experiment?Â ğŸ¯

Large language models often look correct but secretly **drift**â€”mixing facts, skipping steps, or hallucinating logic as the chain gets longer.  
WFGY introduces four closedâ€‘loop modules (BBMCÂ / BBPFÂ / BBCRÂ / BBAM) to **selfâ€‘heal** those drifts in real time.

This repo lets anyone:

* **Quantify** drift with two simple metrics (Î”S,Â Î»_observe).  
* **Visualise** the gap instantly (two PNG charts).  
* **Swap in any model** (or any guard framework) and reproduce the numbers in <1min.

---

## 2.Â MetricsÂ ğŸ“Š

| Metric | Meaning | Good? |
|--------|---------|-------|
| **Î”S** | Promptâ€‘toâ€‘answer semantic distance (0Â =Â perfect) | lower |
| **Î»_observe** | Percentage of answers with Î”S\<0.4 (passâ€‘rate) | higher |

<br>
<div align="left">
  <img src="images/drift_comparison.png" width="420"/>
  <img src="images/lambda_pass.png"  width="420"/>
</div>
<br>
* **Left chart** â€“ average Î”S: green (WFGY) bar is lower â‡’ answers wander off topic less.  
* **Right chart** â€“ Î»_observe passâ€‘rate: green hits 100% â‡’ WFGY beats baseline on **every** prompt.

---

## 3.Â QuickÂ StartÂ âš¡

### 3â€‘line local run
```bash
pip install -r requirements.txt          # sklearn Â· pandas Â· matplotlib Â· statsmodels
python scripts/run_eval.py               # â†’ data/metrics.csv
python scripts/plot_results.py           # â†’ images/ refreshed charts
````

### Oneâ€‘click Colab

1. Open [https://colab.research.google.com/](https://colab.research.google.com/)
2. `!git clone <YOURâ€‘REPOâ€‘URL>`
3. Run the same three lines above.

---

## 4.Â Swap in your own modelÂ ğŸ”„

1. Put your outputs in

   * `data/baseline_answers.txt`Â Â (WFGYÂ OFF)
   * `data/wfgydrunk_answers.txt`Â (WFGYÂ ON)
     \*âœ§ One answer block per prompt, separated by a blank line.
2. Rerun the two scripts â€“ charts update automatically.
3. **Interpret:** green lower Î”S & higher Î»=your guard beats raw model; if not, drift remains.

### (Optional) Human Îº agreement

```bash
# create data/error_annotations.csv  with columns: Q#,rater1,rater2,rater3 (ok / drift)
python scripts/compute_kappa.py         # prints FleissÂ Îº
```

---

## 5.Â Folder layoutÂ ğŸ—‚ï¸

```
semantic-drift-demo/
â”œâ”€ data/
â”‚   â”œâ”€ test_prompts.json      # 30 prompts (from WFGY PDF, SectionÂ 3)
â”‚   â”œâ”€ baseline_answers.txt   # answers with WFGY OFF
â”‚   â”œâ”€ wfgydrunk_answers.txt  # answers with WFGY ON
â”‚   â””â”€ metrics.csv            # autoâ€‘generated
â”œâ”€ scripts/
â”‚   â”œâ”€ run_eval.py            # computes Î”S & Î»_observe
â”‚   â”œâ”€ plot_results.py        # draws the two PNG charts
â”‚   â””â”€ compute_kappa.py       # optional Fleiss Îº
â”œâ”€ images/
â”‚   â”œâ”€ drift_comparison.png   # Î”S chart
â”‚   â””â”€ lambda_pass.png        # Î» chart
â””â”€ requirements.txt
```

---

## 6.Â How the code worksÂ ğŸ”

1. **TFâ€‘IDF Î”S**

   * We embed each prompt and answer with TFâ€‘IDF; `1Â â€“Â cosine`Â =Â Î”S.
   * Swap to `sentenceâ€‘transformers` in `run_eval.py` for higherâ€‘fidelity embeddings.

2. **Î»\_observe**

   * If `Î”SÂ <Â threshold` (defaultÂ 0.4) â†’ *pass* for that answer.
   * Î»=(#Â passes)/30.

3. **plot\_results.py**

   * Saves two charts in `images/` (scaled to 420px width for GitHub darkÂ mode).

4. **compute\_kappa.py**

   * Reads three human labels per answer and outputs Fleiss Îº (agreement score).

---

## 7.Â Background: WFGY in one paragraphÂ ğŸ“š

WFGYÂ 1.0 (paper DOIÂ 10.5281/zenodo.15630969) unifies four modules:

| Module   | Function                                                            |
| -------- | ------------------------------------------------------------------- |
| **BBMC** | Measures *semantic residue* (meaning gap) and minimises it.         |
| **BBPF** | Perturbs reasoning paths, encouraging convergent refinement.        |
| **BBCR** | Detects collapse, resets, and **rebirths** the chain midâ€‘inference. |
| **BBAM** | Dampens noisy attention spikes, boosting crossâ€‘modal alignment.     |

The paper reports +22% semantic accuracy and 3.6Ã—stability.
This repo isolates the **semanticâ€‘drift** aspect so anyone can reproduce a slice of those gains without full training.

---

## 8.Â FAQÂ ğŸ™‹â€â™‚ï¸

| Question                          | Answer                                                                                         |
| --------------------------------- | ---------------------------------------------------------------------------------------------- |
| *Why 30 prompts?*                 | Enough to visualise trends; small for fast Colab runs. Extend easily by appending prompts.     |
| *Can I use GPTâ€‘4/Claude outputs?* | Yesâ€”paste them into the two answer files.                                                      |
| *Where is the prompt list from?*  | Adapted from SectionÂ 3 â€œStress Testsâ€ of the WFGYÂ 1.0 PDF.                                     |
| *Charts look blank?*              | Ensure images are committed; GitHub caches aggressivelyâ€”hardâ€‘refresh if needed.                |
| *Î”S too close between models?*    | Switch to sentenceâ€‘transformer embeddings (`use_embed=True` in run\_eval.py) for finer deltas. |

---

## 9.Â LicenseÂ ğŸ“œ

Code released under MIT; prompt set under CCâ€‘BYÂ 4.0 (credit â€œPSÂ BigBig, WFGYÂ 1.0 PDFâ€).
See `LICENSE` for details.

---

Clone, run, swap, publishâ€”**prove your model drifts less.**
For questions or pullâ€‘requests, open an issue or ping **@PSBigBig**. Good luck & happy benchmarking! ğŸš‚ğŸ’¨


---

### ğŸ§­ Explore More

| Module                | Description                                              | Link     |
|-----------------------|----------------------------------------------------------|----------|
| WFGY Core             | WFGY 2.0 engine is live: full symbolic reasoning architecture and math stack | [View â†’](https://github.com/onestardao/WFGY/tree/main/core/README.md) |
| Problem Map 1.0       | Initial 16-mode diagnostic and symbolic fix framework    | [View â†’](https://github.com/onestardao/WFGY/tree/main/ProblemMap/README.md) |
| Problem Map 2.0       | RAG-focused failure tree, modular fixes, and pipelines   | [View â†’](https://github.com/onestardao/WFGY/blob/main/ProblemMap/rag-architecture-and-recovery.md) |
| Semantic Clinic Index | Expanded failure catalog: prompt injection, memory bugs, logic drift | [View â†’](https://github.com/onestardao/WFGY/blob/main/ProblemMap/SemanticClinicIndex.md) |
| Semantic Blueprint    | Layer-based symbolic reasoning & semantic modulations   | [View â†’](https://github.com/onestardao/WFGY/tree/main/SemanticBlueprint/README.md) |
| Benchmark vs GPT-5    | Stress test GPT-5 with full WFGY reasoning suite         | [View â†’](https://github.com/onestardao/WFGY/tree/main/benchmarks/benchmark-vs-gpt5/README.md) |
| ğŸ§™â€â™‚ï¸ Starter Village ğŸ¡ | New here? Lost in symbols? Click here and let the wizard guide you through | [Start â†’](https://github.com/onestardao/WFGY/blob/main/StarterVillage/README.md) |

---

> ğŸ‘‘ **Early Stargazers: [See the Hall of Fame](https://github.com/onestardao/WFGY/tree/main/stargazers)** â€”  
> Engineers, hackers, and open source builders who supported WFGY from day one.

> <img src="https://img.shields.io/github/stars/onestardao/WFGY?style=social" alt="GitHub stars"> â­ [WFGY Engine 2.0](https://github.com/onestardao/WFGY/blob/main/core/README.md) is already unlocked. â­ Star the repo to help others discover it and unlock more on the [Unlock Board](https://github.com/onestardao/WFGY/blob/main/STAR_UNLOCKS.md).

<div align="center">

[![WFGY Main](https://img.shields.io/badge/WFGY-Main-red?style=flat-square)](https://github.com/onestardao/WFGY)
&nbsp;
[![TXT OS](https://img.shields.io/badge/TXT%20OS-Reasoning%20OS-orange?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS)
&nbsp;
[![Blah](https://img.shields.io/badge/Blah-Semantic%20Embed-yellow?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlahBlahBlah)
&nbsp;
[![Blot](https://img.shields.io/badge/Blot-Persona%20Core-green?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlotBlotBlot)
&nbsp;
[![Bloc](https://img.shields.io/badge/Bloc-Reasoning%20Compiler-blue?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlocBlocBloc)
&nbsp;
[![Blur](https://img.shields.io/badge/Blur-Text2Image%20Engine-navy?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlurBlurBlur)
&nbsp;
[![Blow](https://img.shields.io/badge/Blow-Game%20Logic-purple?style=flat-square)](https://github.com/onestardao/WFGY/tree/main/OS/BlowBlowBlow)
&nbsp;
</div>



