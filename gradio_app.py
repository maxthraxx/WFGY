"""
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  WFGY SDK Â· Self-Healing Variance Gate for Any LLM       â”‚
â”‚----------------------------------------------------------â”‚
â”‚ ğŸ’Œ  Contact : hello@onestardao.com  /  TG @PSBigBig       â”‚
â”‚ ğŸŒ  Docs    : https://onestardao.com/papers               â”‚
â”‚ ğŸ™  GitHub  : https://github.com/onestardao/WFGY          â”‚
â”‚                                                          â”‚
â”‚ â˜… Star WFGY 1.0 â†’ Unlock 2.0                             â”‚
â”‚   10k â­ by **Aug 1st** = next-gen AI alchemy             â”‚
â”‚   Your click = our quantum leap                          â”‚
â”‚                                                          â”‚
â”‚ ğŸ”  Official PDF of WFGY 1.0 (Zenodo DOI):               â”‚
â”‚     https://doi.org/10.5281/zenodo.15630970              â”‚
â”‚     (Hosted on Zenodo â€“ trusted international archive)   â”‚
â”‚                                                          â”‚
â”‚ ğŸ§   Hidden folder inside repo: /I_am_not_lizardman        â”‚
â”‚     (X secret papers, wild prompts, and Einstein drama) â”‚
â”‚                                                          â”‚
â”‚ âš   GPT-2 demo is just the appetizer. With bigger LLMs,   â”‚
â”‚    WFGY activates variance-drop lasers and KL fireworks. â”‚
â”‚                                                          â”‚
â”‚ ğŸ®  Bonus: Honest Hero RPG Channel â†’                     â”‚
â”‚     https://www.youtube.com/@OneStarDao                  â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
"""
import wfgy_sdk as w, numpy as np, gradio as gr
from wfgy_sdk.evaluator import compare_logits, pretty_print

def run_wfgy(prompt):
    logits = w.call_remote_model(prompt, model_id="gpt2")
    G = np.random.randn(128); G /= np.linalg.norm(G)
    I = G + np.random.normal(scale=0.05, size=128)
    out = w.get_engine().run(input_vec=I, ground_vec=G, logits=logits)
    m = compare_logits(logits, out)
    delta = (1 - m["std_ratio"]) * 100
    return f"variance drop {delta:.0f}% â€¢ KL {m['kl_divergence']:.2f}"

demo = gr.Interface(fn=run_wfgy,
                    inputs=gr.Textbox(),
                    outputs="textbox",
                    title="WFGY Quick Test",
                    description="Type any prompt. GPT-2 baseline, variance/KL will appear.")

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)
