# ğŸ§  Problem: Long QA Chains Drift Off-Topic

### ğŸ“Context

Even when each individual response is locally correct, many AI agents begin to **semantically drift** as question-answer chains grow longer.

Symptoms include:
- Subtle shifts in topic over 5â€“10 turns
- Forgotten user goals
- Misalignment between early and late context
- The agent redefines the question mid-conversation

---

## ğŸš¨ Why Traditional RAG Fails Here

| Weakness | Description |
|----------|-------------|
| No persistent memory | Most systems treat each QA turn as an isolated prompt context |
| Embedding overlap is fragile | Token overlap does not equal topic stability |
| No tracking of concept flow | Systems canâ€™t trace how topics evolved or when they â€œjumpedâ€ |

---

## âœ… WFGY Solution

WFGY uses **semantic delta tracking** and **Tree-based memory nodes** to detect and prevent drift.

### 1. Semantic Tree Memory  
- Each major concept shift is recorded as a node  
- You can view and backtrack logic flow across topics

### 2. Î”S as Drift Detector  
- When new input diverges from past nodes (Î”S > 0.6), the system logs a new branch  
- This allows structured topic separation and detection of "semantic fatigue"

### 3. Î»_observe Vector  
- Flags if the reasoning is now divergent or chaotic  
- Helps model decide whether to re-anchor or warn the user

---

## ğŸ›  How to Use in TXT OS

```txt
Step 1 â€” Start the console
> Start

Step 2 â€” Ask a sequence of loosely connected questions:
> "What is the policy on returns?"
> "And if it's a gift item?"
> "Now, what about shipping zones?"
> "What if I'm in another country?"

Step 3 â€” Type `view` to inspect the Tree

Youâ€™ll see:
- Nodes logged with Î”S and Î»_observe
- Clear detection of topic shifts
- Logic branching when context drift occurs
````

---

## ğŸ”¬ Example Output

```txt
* Topic: Gift Return Policy | Î”S: 0.22 | Î»: â†’ | Module: BBMC
* Topic: International Shipping | Î”S: 0.74 | Î»: â† | Module: BBPF, BBCR
```

The system realized a **new conceptual frame** was entered and recorded the shift accordingly.

---

## ğŸ”— Related Modules

* `BBMC` â€” Identifies when the concept anchor has shifted
* `BBPF` â€” Supports divergent paths while maintaining logic
* `BBCR` â€” May reroute reasoning or pause to prevent collapse
* `Semantic Tree` â€” Memory structure to prevent context loss

---

## ğŸ“Œ Status

| Feature              | Status                              |
| -------------------- | ----------------------------------- |
| Tree node logging    | âœ… stable                            |
| Î”S-based topic split | âœ… working                           |
| Î»\_observe awareness | âœ… working                           |
| Auto recall or warn  | âš ï¸ partial (manual inspect for now) |

---

## âœï¸ Summary

WFGY doesn't just answer â€” it remembers why you're asking.
If you're tired of long chats forgetting your intent, this is the solution layer you're missing.

